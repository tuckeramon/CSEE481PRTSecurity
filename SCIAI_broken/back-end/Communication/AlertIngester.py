"""
Wazuh Alert Ingester

Reads correlated alerts generated by the Wazuh manager and stores them
in the PLCSecurityAlerts database table for operator review.

DATA FLOW:
    Wazuh Manager (Docker container)
        | generates alerts via rule correlation
    alerts.json (volume-mounted to host)
        | this module reads new lines
    AlertIngester.ingest_new_alerts()
        | parses and inserts
    PRTDB.store_wazuh_alert() -> PLCSecurityAlerts table

FILE POSITION TRACKING:
    The ingester tracks its read position in the alerts.json file to avoid
    re-processing alerts after each poll cycle. Position is stored in a
    companion file (alerts.json.pos) alongside the alerts file.

    On startup, if no position file exists, it seeks to the end of the file
    (only processing NEW alerts going forward, not historical ones).
"""

import json
from datetime import datetime
from typing import Optional, Dict, Any
from pathlib import Path


class AlertIngester:
    """
    Ingests Wazuh alerts from alerts.json into the database.

    Designed to be called periodically from the main polling loop,
    similar to how PLCSecurityMonitor.check_security_status() is called.
    """

    # Default path where Docker volume mounts the alerts file
    DEFAULT_ALERTS_PATH = "C:/wazuh-alerts/alerts.json"

    def __init__(self, prtdb, alerts_path: str = None):
        """
        Initialize the alert ingester.

        :param prtdb: PRTDB instance for database operations
        :param alerts_path: Path to Wazuh alerts.json file
                           (from Docker volume mount)
        """
        self.prtdb = prtdb

        if alerts_path:
            self.alerts_path = Path(alerts_path)
        else:
            self.alerts_path = Path(self.DEFAULT_ALERTS_PATH)

        # Position tracking file (same directory as alerts file)
        self.pos_file = Path(str(self.alerts_path) + ".pos")

        # Current file position (byte offset)
        self._file_position = 0

        # Track file size to detect rotation/truncation
        self._last_file_size = 0

        # Statistics
        self._alerts_ingested = 0
        self._errors = 0

        # Load saved position if available
        self._load_position()

    def _load_position(self):
        """
        Load the last read position from the position file.
        If no position file exists, seek to end of current file.
        """
        try:
            if self.pos_file.exists():
                pos_data = json.loads(self.pos_file.read_text())
                self._file_position = pos_data.get("position", 0)
                self._last_file_size = pos_data.get("file_size", 0)
                print(f"AlertIngester: Resumed at position {self._file_position}")
            elif self.alerts_path.exists():
                # No position file -- start from end (skip historical alerts)
                self._file_position = self.alerts_path.stat().st_size
                self._last_file_size = self._file_position
                self._save_position()
                print(f"AlertIngester: Starting from end of file (pos={self._file_position})")
            else:
                self._file_position = 0
                self._last_file_size = 0
                print(f"AlertIngester: Alerts file not found yet: {self.alerts_path}")
        except Exception as e:
            print(f"AlertIngester: Error loading position: {e}")
            self._file_position = 0

    def _save_position(self):
        """Save current read position to the position file."""
        try:
            pos_data = {
                "position": self._file_position,
                "file_size": self._last_file_size,
                "updated": datetime.now().isoformat()
            }
            self.pos_file.write_text(json.dumps(pos_data))
        except Exception as e:
            print(f"AlertIngester: Error saving position: {e}")

    def _detect_file_rotation(self) -> bool:
        """
        Detect if the alerts file has been rotated or truncated.
        If the current file size is smaller than our last known position,
        the file was likely rotated -- reset position to 0.

        :return: True if rotation was detected
        """
        if not self.alerts_path.exists():
            return False

        current_size = self.alerts_path.stat().st_size
        if current_size < self._file_position:
            print(f"AlertIngester: File rotation detected "
                  f"(size {current_size} < position {self._file_position})")
            self._file_position = 0
            self._last_file_size = current_size
            return True

        self._last_file_size = current_size
        return False

    def ingest_new_alerts(self) -> int:
        """
        Read and process any new alerts from the alerts file.
        Called periodically from main.py's polling loop.

        :return: Number of new alerts ingested
        """
        if not self.alerts_path.exists():
            return 0

        self._detect_file_rotation()

        ingested_count = 0

        try:
            with open(self.alerts_path, 'r', encoding='utf-8') as f:
                f.seek(self._file_position)

                for line in f:
                    line = line.strip()
                    if not line:
                        continue

                    try:
                        alert = json.loads(line)
                    except json.JSONDecodeError as e:
                        print(f"AlertIngester: Skipping malformed JSON: {e}")
                        self._errors += 1
                        continue

                    # Only process alerts from our PLC security rules
                    if not self._is_plc_security_alert(alert):
                        continue

                    if self._process_alert(alert):
                        ingested_count += 1
                        self._alerts_ingested += 1

                # Update position to current file offset
                self._file_position = f.tell()
                self._last_file_size = self.alerts_path.stat().st_size

            if ingested_count > 0:
                self._save_position()
                print(f"AlertIngester: Ingested {ingested_count} new alert(s)")

        except Exception as e:
            print(f"AlertIngester: Error reading alerts file: {e}")
            self._errors += 1

        return ingested_count

    def _is_plc_security_alert(self, alert: dict) -> bool:
        """
        Check if an alert is from our PLC security rules.
        Filters out Wazuh system alerts and other noise.

        :param alert: Parsed alert dictionary
        :return: True if this is a PLC security alert
        """
        rule = alert.get("rule", {})
        groups = rule.get("groups", [])
        return "plc_security" in groups

    def _generate_alert_id(self, alert: dict) -> str:
        """
        Generate a unique ID for a Wazuh alert to prevent duplicates.
        Combines timestamp, rule ID, and agent ID.

        :param alert: Parsed alert dictionary
        :return: Unique alert identifier string
        """
        timestamp = alert.get("timestamp", "")
        rule_id = alert.get("rule", {}).get("id", "")
        agent_id = alert.get("agent", {}).get("id", "")
        return f"{timestamp}_{rule_id}_{agent_id}"

    def _parse_wazuh_timestamp(self, ts_string: str) -> Optional[datetime]:
        """
        Parse Wazuh timestamp format into a datetime object.

        :param ts_string: Timestamp string from Wazuh
        :return: datetime object or None on parse failure
        """
        formats = [
            "%Y-%m-%dT%H:%M:%S.%f%z",
            "%Y-%m-%dT%H:%M:%S%z",
            "%Y-%m-%dT%H:%M:%S.%f",
            "%Y-%m-%dT%H:%M:%S",
        ]
        for fmt in formats:
            try:
                return datetime.strptime(ts_string, fmt)
            except ValueError:
                continue

        print(f"AlertIngester: Could not parse timestamp: {ts_string}")
        return None

    def _process_alert(self, alert: dict) -> bool:
        """
        Process a single Wazuh alert and store it in the database.

        :param alert: Parsed alert dictionary from alerts.json
        :return: True if stored successfully
        """
        try:
            rule = alert.get("rule", {})
            agent = alert.get("agent", {})
            data = alert.get("data", {})

            alert_id = self._generate_alert_id(alert)
            wazuh_ts = self._parse_wazuh_timestamp(alert.get("timestamp", ""))

            result = self.prtdb.store_wazuh_alert(
                wazuh_alert_id=alert_id,
                wazuh_rule_id=str(rule.get("id", "")),
                wazuh_rule_level=int(rule.get("level", 0)),
                wazuh_rule_description=rule.get("description", ""),
                wazuh_rule_groups=",".join(rule.get("groups", [])),
                agent_id=agent.get("id"),
                agent_name=agent.get("name"),
                agent_ip=agent.get("ip"),
                plc_ip=data.get("plc_ip"),
                event_type=data.get("event_type"),
                severity=data.get("severity"),
                event_message=data.get("message"),
                previous_state=data.get("previous_state"),
                current_state=data.get("current_state"),
                raw_alert=json.dumps(alert),
                wazuh_timestamp=wazuh_ts
            )

            return result > 0

        except Exception as e:
            print(f"AlertIngester: Error processing alert: {e}")
            self._errors += 1
            return False

    def get_stats(self) -> dict:
        """
        Return ingestion statistics.

        :return: Dictionary with ingestion stats
        """
        return {
            "alerts_ingested": self._alerts_ingested,
            "errors": self._errors,
            "file_position": self._file_position,
            "alerts_file": str(self.alerts_path),
            "file_exists": self.alerts_path.exists()
        }
